# Contemporary Issues In Data

# ChatGPT's Launch and its Ability to Upend Education and Government for Better or for Worse
In this document, I discuss two articles about ChatGPT, a newly launched chatbot with the potential to upend multiple areas of life. I will cover the two articles' opposing viewpoints on ChatGPT in education and government.

## Article 1
In the New York Times' [Don't ban ChatGPT in schools. Teach with it] (https://www.nytimes.com/2023/01/12/technology/chatgpt-schools-teachers.html?action=click&pgtype=Article&state=default&module=styln-artificial-intelligence&variant=show&region=MAIN_CONTENT_1&block=storyline_top_links_recirc), the writer (Kevin Roose) acknowledges that the fear of ChatGPT being used for cheating on homework is valid, but believes the chatbot's potential as a tool for education outweighs those risks. In one case, while ChatGPT may be used by students to write essays for them or answer homework questions, the chatbot has also helped teachers with grading their students' papers and providing detailed feedback. This shows that both sides (students and teachers) could benefit from the tool. As such, there won't be an asymmetric dynamic since both sides can use it. Of course, this is only one possible situation, and the writer states there are legitimate questions surrounding the ethics of this A.I tool. For example, artifically generated answers may not always be accurate, especially because ChatGPT does not use the internet to provide responses, which means the chatbot won't be up to date on current events. Additionally, the existence of this tool means teachers may have to restructure their classes to provide assignments where ChatGPT won't be very helpful. This would include more in-person, handwritten work, and other tasks which could be done without electronic devices to prevent access to the chatbot, thereby putting more pressure on teachers.
Despite these worries, Roose centers his opinion on the premise that A.I chatbots are a part of the future, and banning them simply won't work. It would be better to work with them rather than around them. Students can easily find ways of accessing ChatGPT outside of class, even if the school blocks the website on its network. For teachers, policing this behavior is even more time consuming than adjusting to it, and could create adversarial relationships with their students. I agree with this argument the most, because I have seen firsthand that banning anything in high school was not always enforceable, and students can be extremely resourceful in finding ways to get around these rules. On top of this, today's students will need to know how to work with A.I tools because they will only become more prominent in the years to come. Understanding how these tools can be used, and how to prevent misuse and biases is also a part of education and preparing these students for the future.

## Article 2
Contrary to the more optimistic view on ChatGPT in the NY Times' article, the New York Times' [How ChatGPT Hijacks Democracy] (https://www.nytimes.com/2023/01/15/opinion/ai-chatgpt-lobbying-democracy.html) take a dimmer view on the emergence of ChatGPT, especially in the political scene. ChatGPT's ability to draft documents and messages means it can automatically generate comments on news articles and social media, thereby swaying public opinion. For example, such a chatbot could mimic the sort of election interference that occurred in 2016 but with less human drive behind it. While this is a more extreme case, it is a strong example of how A.I like chatbots can sway data and opinions, which in the long run will affect government. This article illustrates the impact a system like ChatGPT can have on lobbying with legislators. For instance, an A.I system could identify legislators with the most leverage over a certain issue, as well as those whose votes are the deciding factor for the bill on that issue. Afterwards, a chatbot like ChatGPT can craft messages to target those individuals (similar to human lobbyists) with better scope, such as through constituent calls. Overall, A.I lobbyists would do similar work to human ones and pose a similar threat. However, the A.I lobbyist could do the job more quickly, efficiently, and cheaply, which is significant in a time where narratives shift quickly in response to chaotic events. There are some benefits to such lobbying, such as A.I lobbying being more accessible to those who cannot afford to pay expensive K-street firms in DC. On the other hand, it is still not immune from being powered through money. A.I lobbying can do a better job of identifying which legislator can sway a vote, or identify a PAC to fund certain campaigns, but the power of pursuing this still lays with the powerful and influential. With such technology, they can still achieve their goals in goals in government, whereas those without the cash wouldn't. As a result, the inequality in this accessibility doesn't necessarily decrease.
I believe there are both positive and negative aspects with ChatGPT in a political environment. This kind of chatbot definitely has the potential to make political targeting easier and faster for everyone. However, I agree with the article's view that ChatGPT essentially hijacks lobbying to the point where it completely upends the process, unleashing all kinds of consequences. It is another tool that can sway public opinion to the extent that it may no longer represent the actual views, especially if the powerful and wealthy play a larger role in using it to shift opinion.

